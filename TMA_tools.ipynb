{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/auri/anaconda3/envs/fastaiAP/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from fastai.distributed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "import sklearn.metrics as skm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 170)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import openslide\n",
    "from numpy import asarray\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be used for WSI images (not TMAs)\n",
    "class WSI:\n",
    "    def __init__(self, svs_fn):\n",
    "        self.svs_fn = svs_fn\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_tile( x,y , size= (300,300) , level = 0, path = None, svs_fn = None):\n",
    "\n",
    "        slide = None\n",
    "\n",
    "        try:\n",
    "            slide = openslide.OpenSlide(os.path.join(path, svs_fn + '.svs'))\n",
    "            #print(f'reading: {tma}')\n",
    "        except: \n",
    "            print(f'failed: {os.path.join(path, svs_fn + \".svs\")}')\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "        img = array(slide.read_region((x,y),level,size))\n",
    "\n",
    "\n",
    "        if (len(img.shape) > 2 and img.shape[2] > 3):\n",
    "            img = img[:,:,:3] #remove last image dimension, so to have 3 channels and not 4 (hue)\n",
    "\n",
    "        #if Spot.check_scarce_tissue(image):\n",
    "        #    return np.nan\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMA:\n",
    "    diameter_spot = 1200\n",
    "    def __init__(self, tma_path, file, img_path_tif):\n",
    "        self.meta_fn = file\n",
    "        self.meta_path = tma_path\n",
    "        self.img_path_tif = img_path_tif\n",
    "        if 'Series' in file: #v2 Qpath\n",
    "            self.name = file.split(' - ')[1].strip('.tif')\n",
    "        else:\n",
    "            self.name = file.strip('.txt')[len('TMA results - '):]\n",
    "        #self.spots = None #self.load_spots_meta()\n",
    "        #self.img_tif = None #self.load_img_tif()\n",
    "\n",
    "    @property\n",
    "    def img_tif(self):\n",
    "        self.__img_tif = self.load_img_tif()\n",
    "        return self.__img_tif\n",
    "    \n",
    "    @property\n",
    "    def spots(self):\n",
    "        self.__spots = self.load_spots_meta()\n",
    "        return self.__spots\n",
    "        \n",
    "    def load_tma_meta(self):\n",
    "        df1 = None\n",
    "        try:\n",
    "            df1 = pd.read_csv(os.path.join(self.meta_path, self.meta_fn), names=['fn', 'missing','X', 'Y', 'ID', 'notes'], sep='\\t', skiprows=[0])\n",
    "            \n",
    "            if 'tif' in df1.fn[0]: #Qpath v2 Image\tName\tMissing\tCentroid X µm\tCentroid Y µm\tUnique ID\n",
    "                df1 = pd.read_csv(os.path.join(self.meta_path, self.meta_fn), names=['TMA', 'fn', 'missing','X', 'Y', 'ID'], sep='\\t', skiprows=[0])\n",
    "            \n",
    "            \n",
    "            if self.name == 'TMA20-013':\n",
    "                df1.ID = df1.ID.str.replace(r'-.*', '', regex = True)\n",
    "                \n",
    "        except:\n",
    "            print(os.path.join(self.meta_path, self.meta_fn))\n",
    "        return df1\n",
    "    \n",
    "    def load_img_tif(self):\n",
    "        a = None\n",
    "        try:\n",
    "            #print(f\"opening tif: {os.path.join(self.img_path_tif, self.name + '.tif')}\")\n",
    "            a = openslide.OpenSlide(os.path.join(self.img_path_tif, self.name + '.tif'))\n",
    "        except: \n",
    "            print(f\"BAD {self.name}.tif\")\n",
    "        return a\n",
    "    \n",
    "    def load_spots_meta(self):\n",
    "        spots = []\n",
    "        for index, rows in self.load_tma_meta().iterrows():\n",
    "            spots.append(Spot(self.diameter_spot, \n",
    "                              rows.fn, rows.missing, (rows.X, rows.Y), str(rows.ID),\n",
    "                        self.meta_path, self))\n",
    "        return spots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spot: \n",
    "    def __init__(self, diameter, name, missing, center, ID, img_path_jpg, tma):\n",
    "        self.path_jpg = img_path_jpg\n",
    "        self.diameter = diameter #in micrometers\n",
    "        self.name = name\n",
    "        self.center = center #in micrometers\n",
    "        self.missing = missing\n",
    "        self.ID = ID\n",
    "        self.TMA = tma\n",
    "        self.tiles = []\n",
    "        \n",
    "    def load_img_jpg(self):\n",
    "        s = openslide.ImageSlide(os.path.join(self.path_jpg, self.name + '.jpg'))\n",
    "        #regions to be read with method s.read_region()\n",
    "        return s\n",
    "    \n",
    "    #get spot center coordinates in pixels\n",
    "    def get_center_pixel(self):\n",
    "        tma = self.TMA.img_tif\n",
    "        c_x, c_y = self.center \n",
    "        mpp_x, mpp_y = float(tma.properties['openslide.mpp-x']), float(tma.properties['openslide.mpp-y']) #mpp  - 0.25  micras per pixel\n",
    "        pc_x, pc_y = int(c_x / float(mpp_x)),int(c_y / float(mpp_y))\n",
    "        return pc_x, pc_y\n",
    "    \n",
    "    #return radious in pixels both at full magnification (level = 0) and at a given zoom-out level\n",
    "    def get_radious_pixel(self, level):\n",
    "        tma = self.TMA.img_tif\n",
    "        mpp_x, mpp_y = float(tma.properties['openslide.mpp-x']), float(tma.properties['openslide.mpp-y'])\n",
    "        #mpp = (mpp_x**2 + mpp_y**2)**0.5\n",
    "        pspot_radio = int(self.diameter/ mpp_x / 2 )\n",
    "        pzoom_radio = int( pspot_radio/ 2**level ) #with each increasing level the image is reduced half size \n",
    "        return pspot_radio, pzoom_radio\n",
    "    \n",
    "    #return spot circunference's north and sud y-coordinates (absolute positions in level 0) \n",
    "    #given a relative position from 0 (left) to 1 (right) in the spot diameter in axis x\n",
    "    def get_circle_coordinates_pixel(self, rel_pos_diameter_x = .5): #return by default the y-coordinates for x fixed at center\n",
    "        pc_x, pc_y = self.get_center_pixel()\n",
    "        pspot_radio, _ = self.get_radious_pixel(0)\n",
    "        x = int(pc_x - pspot_radio + rel_pos_diameter_x*(pspot_radio*2))\n",
    "        if (( x + pspot_radio < pc_x) or ( x - pspot_radio > pc_x)): #x should be in circle diameter (pc_x - pspot_radio, pc_x + pspot_radio)\n",
    "            return x, np.nan, np.nan\n",
    "        root = (pspot_radio**2 - (x - pc_x)**2)**0.5\n",
    "        y_north = int( -root + pc_y)\n",
    "        y_sud = int( root + pc_y)\n",
    "        return x, y_north, y_sud\n",
    "    \n",
    "    #check (true or false) if there is scarce tissue in an image\n",
    "    @staticmethod\n",
    "    def check_scarce_tissue(tile_image, threshold = 230, verbose = False, ret = 'bool'): \n",
    "        s = np.mean(tile_image, axis = 2) #collapse 3 color channels into 1 by mean\n",
    "        s = s[(s > 0)] #remove black mask (value == 0)\n",
    "        r = s.mean()  \n",
    "        if verbose:\n",
    "            print(r)\n",
    "        if ret == 'mean':\n",
    "            return r\n",
    "        return r >= threshold #completely white = 255\n",
    "       \n",
    "    \n",
    "    #return an image tile from the spot where x,y is the left-sup corner of the tile\n",
    "    #for reference for current scanned tifs properties, level 0 is fully magnified image and for level 4 encloses one spot of diameter 1.2 micrometers\n",
    "    def get_tile(self, x,y , size=(300,300) , level = 4, path = None, tif_name = None):\n",
    "        \n",
    "        tma = None\n",
    "        if (tif_name == None): tma = self.TMA.img_tif\n",
    "        else:\n",
    "            try:\n",
    "                tma = openslide.OpenSlide(os.path.join(path, tif_name + '.tif'))\n",
    "            except: \n",
    "                print(tif_name + '.tif')\n",
    "        \n",
    "        img = array(tma.read_region((x,y),level,size))\n",
    "        \n",
    "        \n",
    "        if (len(img.shape) > 2 and img.shape[2] > 3):\n",
    "            img = img[:,:,:3] #remove last image dimension, so to have 3 channels and not 4 (hue)\n",
    "        \n",
    "        #if Spot.check_scarce_tissue(image):\n",
    "        #    return np.nan\n",
    "        return img\n",
    "\n",
    "   \n",
    "        \n",
    "    \n",
    "    #check (true or false) that tile (defined by left sup coordinate and size in a zoom level) is enclosed in a box defined by the 4 spot poles \n",
    "    def check_tile_in_spot(self, x,y,size=(300,300) , level = 4):\n",
    "        spot_poles = (self.get_circle_coordinates_pixel(0)[0], #left\n",
    "                  self.get_circle_coordinates_pixel(1)[0],  #right\n",
    "                  self.get_circle_coordinates_pixel(0.5)[1], #north\n",
    "                  self.get_circle_coordinates_pixel(0.5)[2]) #sud\n",
    "        if (x < spot_poles[0]) or (y < spot_poles[2] ) or (x + size[0]*(2**level) > spot_poles[1] ) or (y + size[1]*(2**level) > spot_poles[3]):\n",
    "            return False, spot_poles\n",
    "        else:\n",
    "            return True, spot_poles\n",
    "        \n",
    "        \n",
    "    #given a tile size in pixels and zoom level then sample all possible tiles from spot \n",
    "    #with a given overlap (0 to <1)\n",
    "    #return all tiles (defined by sup-lef corner coordinates, size and level) \n",
    "    #enclosed in box-spot with enough tissue \n",
    "    def sample_tiles(self, size = (300,300), level = 4, overlap = .2):\n",
    "        self.tiles = []\n",
    "        pspot_radio, _ = self.get_radious_pixel(level)\n",
    "        spot_tile_ratio = pspot_radio * 2 / size[0] \n",
    "        spot_tile_ratio_by_zoom = spot_tile_ratio / 2**level \n",
    "        stride_norm = 1 - overlap\n",
    "        #print(np.arange(0,1,stride_norm/spot_tile_ratio_by_zoom))\n",
    "        for i_x in np.arange(0,1,stride_norm/spot_tile_ratio_by_zoom): \n",
    "            x, y_north, y_sud = self.get_circle_coordinates_pixel(i_x)\n",
    "            if (y_sud-y_north == 0): #intersection of ecuador with circunference\n",
    "                if self.check_tile_in_spot(x, int(y_north), size, level)[0]:\n",
    "                    self.tiles.append([x, int(y_north), size, level])\n",
    "                if self.check_tile_in_spot(x, int(y_north) - pspot_radio, size, level)[0]:\n",
    "                    self.tiles.append([x, int(y_north) - pspot_radio, size, level])\n",
    "            else:\n",
    "                for j in np.arange(y_north, y_sud, stride_norm *size[1]*(2**level) ): \n",
    "                    if self.check_tile_in_spot(x, int(j), size, level)[0]:\n",
    "                        self.tiles.append([x, int(j), size, level])\n",
    "\n",
    "        return self.tiles\n",
    "    \n",
    "    \n",
    "\n",
    "    #given a zoom level it returns the box enclosing only this spot\n",
    "    def get_enclosing_box(self, level, return_image = True):\n",
    "        pspot_radio, pzoom_radio = self.get_radious_pixel(level)\n",
    "        #print(pzoom_radio)\n",
    "        pc_x, pc_y = self.get_center_pixel()\n",
    "        x,y,size,level = pc_x - pspot_radio, pc_y - pspot_radio,  (pzoom_radio * 2, pzoom_radio * 2), level\n",
    "        if return_image: \n",
    "            tile = self.get_tile(x,y,size,level )\n",
    "        else: \n",
    "            tile = [x,y,size,level]\n",
    "        return tile\n",
    "    \n",
    "    #given a tile defined by [x,y,size,zoom_level] return an enlarged tile \n",
    "    #the enlarged tile is defined as the minimal tile needed to enclose original tile rotated around the tile center by n_degrees (values 0 to 90º)\n",
    "    #for default rotation (45º) the enlargement factor is hence equal to hypothenuse of a side of length 1 triangle (1/sin 45º = 2^(1/2))\n",
    "    @staticmethod\n",
    "    def enlarge_tile(x,y, original_tile_size = (300,300), level = 0, n_degrees = 45 ):\n",
    "        #calculate the enlargement factor for rotation degrees\n",
    "        enlargement_factor = np.sin(np.deg2rad(n_degrees + 45))/np.sin(np.deg2rad(45))\n",
    "        #calculate half side length of original tile in pixels in level 0 (max zoom-in or pixels in source image)\n",
    "        half_side_length = (2**level) * (original_tile_size[0]/ 2)  #it is assuming tile sizes are always square\n",
    "        #calculate enlarged side length of new enclosing tile to include original tile rotated n degrees\n",
    "        new_half_side_length = half_side_length * enlargement_factor\n",
    "        #calculate new upper-left corner coordinate (new_half_side_lenghth need to be substracted because origin of image in pixels is always upper-left image corner)\n",
    "        x_new,y_new = int(x + (half_side_length - new_half_side_length)), int(y + (half_side_length - new_half_side_length) )\n",
    "        return [x_new,y_new,(int(original_tile_size[0] * enlargement_factor), int( original_tile_size[0] * enlargement_factor) ),level]\n",
    "        \n",
    "    \n",
    "    #Given an image, define the maximum circle enclosed in the image \n",
    "    #and return the image with areas outside the circle masked in black (value 0)\n",
    "    @staticmethod\n",
    "    def mask_outside_of_enclosed_cyrcle(img):\n",
    "        \n",
    "        hh, ww = img.shape[:2]\n",
    "        hh2 = hh // 2\n",
    "        ww2 = ww // 2\n",
    "\n",
    "        # define circle\n",
    "        radius = hh2\n",
    "        xc = hh2\n",
    "        yc = ww2\n",
    "\n",
    "\n",
    "\n",
    "        # draw filled circle in white on black background as mask\n",
    "        img = np.array(img)\n",
    "        if (img.shape[2] > 3):\n",
    "            img = img[:,:,:3] #remove last image dimension, so to have 3 channels and not 4 (hue)\n",
    "        mask = np.zeros_like(img)\n",
    "        mask = cv2.circle(mask, (xc,yc), radius, (255,255,255), -1)\n",
    "\n",
    "        # apply mask to image\n",
    "        result = cv2.bitwise_and(img, mask)\n",
    "\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID', 'CENTROrecod',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_ID_EPI2_PRY',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_EPICOLON', 'NºEpicolon',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_IMS',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_IHQ', 'Lynch', 'LynchIMS',\n",
       "       'IHQpatol', 'Epicolon1+2IHQ-IMS-maria paper lynlike_MMR',\n",
       "       'ihq_mlh1', 'ihq_msh2', 'ihq_msh6', 'ihq_pms2', 'methyMLH1',\n",
       "       'mutacio', 'VSI', 'msh2_gen', 'mlh1_gen', 'mlp_msh2', 'mut_msh2',\n",
       "       'mlp_mlh1', 'mut_mlh1', 'beth', 'r_beth', 'amst_1', 'edat',\n",
       "       'edad1ªneo', 'r_beth_1', 'Neoprevlynch', 'NeoprevlynchR',\n",
       "       'ant_endo', 'sexe', 'neoplasi', 'edat_ant', 'aden_pre', 'clínica',\n",
       "       'interven', 'técnica_', 'localtum', 'localtumagrup',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_t',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_n',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_m', 'estadiat', 'dukes',\n",
       "       'dukes_r', 'infirec', 'moc', 'grado_di', 'famLynchMaria',\n",
       "       'fam1ºGLynchMaria', 'famLynch', 'famBeth', 'familiar1', 'sexo1',\n",
       "       'edaddiag1', 'localiza1', 'famili2', 'sexo2', 'edaddi2', 'locali2',\n",
       "       'famili3', 'sexo3', 'edaddi3', 'locali3', 'famili4', 'sexo4',\n",
       "       'edaddi4', 'locali4', 'famili5', 'sexo5', 'edaddi5', 'locali5',\n",
       "       'famili6', 'sexo6', 'edaddi6', 'locali6', 'famCCR', 'f1ccr',\n",
       "       'nºfam', 'tip_n_pr', 'ccrprevi', 'ccr_sin', 'ccr_s_m', 'pol_sinc',\n",
       "       'histolog', 'aden_sin', 'amst_2', 'cchnp', 'fam_ccr', 'edat_fam',\n",
       "       'fam1_ce', 'ce_pr_si', 'endometr', 'fam_cchn', 'edat_f1',\n",
       "       'fam_cc2', 'fam1_ccr', 'fam1_end', 'f1ccr50', 'fam1_cch',\n",
       "       'fam1_c1', 'edat_f4', 'f1b_50', 'r_beth_2', 'r_beth_3', 'r_beth_4',\n",
       "       'r_beth_5', 'FILTER_$', 'COD_DTS',\n",
       "       'Epicolon1+2IHQ-IMS-maria paper lynlike_TMA', 'SPOTS',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_ID_EPI2_PRY', 'enPXLAB',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_EPICOLON', 'hospital',\n",
       "       'numero caso', 'numEpicolon2', 'RECIMORT', 'TNMRECI', 'lorecid',\n",
       "       'recidccragr', 'CIMP', 'KRAS', 'BRAF',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_MMR', 'Subtipo', 'TipoMUT',\n",
       "       'Nombre', 'sexo', 'edad', 'Fechadx', 'Fechaqx',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_IHQ',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_IMS',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_t',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_n',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_m', 'TNMagrup', 'localizacion',\n",
       "       'ttoqt', 'ttocompl', 'ttocomplagr', 'tipoqtagrup', 'FU_CAPE',\n",
       "       'OXALI', 'QT1linea', 'FUvsFolfox', 'Biologicos', 'sup3qt', 'qt1',\n",
       "       'qt2', 'qt3', 'FECINIQT', 'FECFINQT', 'Rtagrup', 'fechreci',\n",
       "       'Ttorecidiva', 'tiempsegact', 'Fechafin', 'ILEact', 'ffinsegu',\n",
       "       'estfseagrup', 'caumuertagrup',\n",
       "       'BaseEP1y2actualizada2016-OSCAR-def_TMA'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OLD ddbb\n",
    "path = 'SPOTS/TMA06-03.qptma.data/'\n",
    "#df_old= pd.read_csv('DTS2020 ALENDA.xlsx - DTS2020_ALENDA.csv', )\n",
    "df_old = pd.read_excel('DTS2020 ALENDA.xlsx', )\n",
    "df_old_labels = df_old[['COD_DTS','Epicolon1+2IHQ-IMS-maria paper lynlike_IMS','LynchIMS','ihq_mlh1','dukes_r',\n",
    " 'TNMagrup','BaseEP1y2actualizada2016-OSCAR-def_n', 'grado_di','infirec','moc',\n",
    "'edat', 'sexe','ccr_sin','aden_sin','r_beth_4',\n",
    "'RECIMORT','KRAS','localizacion','fechreci','ILEact','estfseagrup']]\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#print(df_old.head())\n",
    "df_old.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         {E00026, 26, E26}\n",
       "1              {27, E00027}\n",
       "2         {42, E42, E00042}\n",
       "3         {E43, 43, E00043}\n",
       "4              {E00062, 62}\n",
       "               ...         \n",
       "1684           {nan, 28094}\n",
       "1685         {E01326, 1326}\n",
       "1686         {3102, E03102}\n",
       "1687            {nan, 5085}\n",
       "1688    {nan, E08175, 8175}\n",
       "Name: mixID, Length: 1689, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old[(df_old['NºEpicolon'].isna()) & (df_old['BaseEP1y2actualizada2016-OSCAR-def_ID_EPI2_PRY'].isna()) & (df_old['COD_DTS'].isna()) ]\n",
    "df_old['mixID'] = df_old.apply(lambda x: {x['NºEpicolon'], x['BaseEP1y2actualizada2016-OSCAR-def_ID_EPI2_PRY'], x['COD_DTS']}, axis = 1)\n",
    "df_old['mixID'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def f(x):\n",
    "    x = [x] if not isinstance(x, list) else x\n",
    "    \n",
    "    found = set()\n",
    "    for s in x:\n",
    "        \n",
    "        m = re.search('([1-9]\\d+)', str(s))\n",
    "        if m:\n",
    "            found.add(m.group(1))\n",
    "    \n",
    "    return list(found)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_old['new_id'] = df_old['mixID'].apply(lambda x: f(x))\n",
    "#df_old.new_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('DTS2020_08_10.csv', )\n",
    "#add additional clinical variables from old database \n",
    "df = df.merge(df_old_labels.loc[df_old_labels.COD_DTS.isna() == False], on = 'COD_DTS', how = 'left')\n",
    "#df.to_csv('cDTS2020_08_10.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "df_labels = df\n",
    "#print(df_labels.columns)\n",
    "\n",
    "#print(df_labels.shape, df_old.shape)\n",
    "\n",
    "QuProject_path = \"SPOTS/save-jul20\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load only clinical info of New TMAs provided on March 21 and project with new TMAs\n",
    "new_TMAs = True\n",
    "if new_TMAs:\n",
    "    df_marc21 = pd.read_csv('NUEVOS_HGUA_Mar21.csv')\n",
    "    df_marc21['LIST_ID'] = df_marc21.BIOPSIA\n",
    "    #fix id mismatch between plantilla TMA20-013 and clinical data provided (removed sequence of 0s in clinical data)\n",
    "    df_marc21.loc[df_marc21.tif_fn == 'TMA20-013', ['LIST_ID']] = df_marc21.LIST_ID.loc[df_marc21.tif_fn == 'TMA20-013'].str.replace(r'00+', '',n = 1, regex = True)\n",
    "\n",
    "    df_marc21['patient_ID'] = df_marc21.LIST_ID\n",
    "    df_marc21['label'] = df_marc21.MMR\n",
    "    df_marc21['COD_DTS'] = df_marc21.BIOPSIA\n",
    "    \n",
    "    \n",
    "    df_labels = df_marc21\n",
    "    QuProject_path = \"SPOTS/save-mar21\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List available spots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tmas = []\n",
    "spots = []\n",
    "for root, dirs, files in os.walk(QuProject_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and re.search('TMA20-013', file) :  #To process all tif files replace regex by .*\n",
    "            tma = TMA(root, file, 'DTS2019')\n",
    "            spots.append([s.ID for s in tma.spots])\n",
    "            tmas.append(tma)\n",
    "            \n",
    "\n",
    "spots = [i for l in spots for i in l]  \n",
    "\n",
    "sp = set(spots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spots 80\n",
      "number of different biopsies in spots 40\n"
     ]
    }
   ],
   "source": [
    "#noexport\n",
    "print(f'number of spots {len(spots)}')\n",
    "print(f'number of different biopsies in spots {len(sp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(df_old.COD_DTS) & set(df.COD_DTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients in spot but not in ddbb:  40\n",
      "patients in ddbb but not in spots:  1890\n",
      "different patients - infered from id groups  2213\n",
      "different patients using COD_DTS  1889\n",
      "different patients - infered from id groups, with MMR deficits  299\n",
      "different patients using COD_DTS with MMR deficits  221\n"
     ]
    }
   ],
   "source": [
    "#noexport\n",
    "#spots id may arbitrarily match different types of id numbers for same patient (biopsy, cod_dts, etc,.. ), \n",
    "m = 'patients in spot but not in ddbb:'\n",
    "m_ = 'patients in ddbb but not in spots:'\n",
    "p = 'different patients - infered from id groups'\n",
    "p_= 'different patients using COD_DTS'\n",
    "MMR = 'different patients using COD_DTS with MMR deficits'\n",
    "MMR_ = 'different patients - infered from id groups, with MMR deficits'\n",
    "print (f'{m}  {len(sp - set(df.LIST_ID.values))}')\n",
    "print (f'{m_}  {len(set(df.COD_DTS.values) - sp ) }')\n",
    "print (f'{p}  {df.DERIVED_GROUP_ID.nunique()}')\n",
    "print (f'{p_}  {df.COD_DTS.nunique()}')\n",
    "print (f'{MMR_}  {df.loc[df.MMR == 1].DERIVED_GROUP_ID.nunique()}')\n",
    "print (f'{MMR}  {df.loc[df.MMR == 1].COD_DTS.nunique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id in spots but not in bbdd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'06B14684', '08B14870'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "#id in spots but not in bbdd\n",
    "print('id in spots but not in bbdd')\n",
    "sp - set(df_labels.LIST_ID.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = pd.DataFrame(columns=['tile', 'tile_rot_augmentation', 'path','tif_fn', 'patient_ID','spot_ID','label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spot(spot,label = 'MMR', size=(300,300) ,level=3, verbose = False, overlap = .0, skip_scarce_tissue = False):\n",
    "    m = ''\n",
    "    ds = pd.DataFrame(columns=['tile', 'tile_rot_augmentation','path','tif_fn', 'patient_ID','spot_ID','label', 'spot_coord'])\n",
    "    \n",
    "    tiles = [] \n",
    "    if (level >= 4): #level 4 is max zoom level out for each spot in TMAs provided\n",
    "        tiles = [spot.get_enclosing_box(level, return_image = False)]\n",
    "        m = str(spot.TMA.name) +',' + str(spot.name) + ','\n",
    "    else: \n",
    "        tiles = spot.sample_tiles(size = (300,300), level = level, overlap = .0)\n",
    "\n",
    "    for tile in tiles:\n",
    "        enlarged_tile = Spot.enlarge_tile(*tile)\n",
    "        #only add tile if its generated image is valid and there is enough tissue\n",
    "        img = spot.get_tile(*enlarged_tile)\n",
    "        result = Spot.mask_outside_of_enclosed_cyrcle(img)\n",
    "        scarce_tissue = False\n",
    "        if skip_scarce_tissue:\n",
    "            scarce_tissue = Spot.check_scarce_tissue(result)\n",
    "            if scarce_tissue: \n",
    "                m = m + ','+ str(spot.ID) + ',scarce tissue '\n",
    "                if verbose: print(m)\n",
    "        if len(img.shape) != 3:\n",
    "            m = m + ','+ str(spot.ID) + ',not valid image '\n",
    "            if verbose: print(m)\n",
    "        if len(img.shape) == 3 and scarce_tissue == False:\n",
    "            s = df_labels.loc[df_labels['LIST_ID'] == str(spot.ID)]\n",
    "\n",
    "            if (s.shape[0] != 0):\n",
    "                if label == 'EDAD':\n",
    "                    l = float(str(s.iloc[0][label]).replace(',','.'))\n",
    "                else:\n",
    "                    l = s.iloc[0][label]\n",
    "                cod_dts = s.iloc[0].COD_DTS\n",
    "\n",
    "                ds = ds.append({'tile': tile, 'tile_rot_augmentation': enlarged_tile, 'path': tma.img_path_tif, 'tif_fn': tma.name, 'patient_ID': cod_dts,'spot_ID': spot.ID,'label': l , 'spot_coord': spot.name}, ignore_index=True)          \n",
    "\n",
    "            else:\n",
    "                m = m + ','+ str(spot.ID) +',not in bbdd '\n",
    "                if verbose: print(m)\n",
    "            \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tma(tma,label = 'MMR', level=3, verbose = False, skip_scarce_tissue = True):\n",
    "    m = ''\n",
    "    ds = pd.DataFrame(columns=['tile', 'tile_rot_augmentation','path','tif_fn', 'patient_ID','spot_ID','label', 'spot_coord'])\n",
    "    for spot in tma.spots:\n",
    "        tiles = [] \n",
    "        if (level >= 4): #level 4 is max zoom level out for each spot in TMAs provided\n",
    "            tiles = [spot.get_enclosing_box(level, return_image = False)]\n",
    "            m = str(spot.TMA.name) +',' + str(spot.name) + ','\n",
    "        else: \n",
    "            tiles = spot.sample_tiles(size = (300,300), level = level, overlap = .0)\n",
    "            \n",
    "        for tile in tiles:\n",
    "            enlarged_tile = Spot.enlarge_tile(*tile)\n",
    "            #only add tile if its generated image is valid and there is enough tissue\n",
    "            img = spot.get_tile(*enlarged_tile)\n",
    "            result = Spot.mask_outside_of_enclosed_cyrcle(img)\n",
    "            scarce_tissue = False\n",
    "            if skip_scarce_tissue:\n",
    "                scarce_tissue = Spot.check_scarce_tissue(result)\n",
    "                if scarce_tissue: \n",
    "                    m = m + ','+ str(spot.ID) + ',scarce tissue '\n",
    "                    if verbose: print(m)\n",
    "            if len(img.shape) != 3:\n",
    "                m = m + ','+ str(spot.ID) + ',not valid image '\n",
    "                if verbose: print(m)\n",
    "            if len(img.shape) == 3 and scarce_tissue == False:\n",
    "                s = df_labels.loc[df_labels['LIST_ID'] == str(spot.ID)]\n",
    "                \n",
    "                if (s.shape[0] != 0):\n",
    "                    if label == 'EDAD':\n",
    "                        l = float(str(s.iloc[0][label]).replace(',','.'))\n",
    "                    else:\n",
    "                        l = s.iloc[0][label]\n",
    "                    cod_dts = s.iloc[0].COD_DTS\n",
    "                    \n",
    "                    ds = ds.append({'tile': tile, 'tile_rot_augmentation': enlarged_tile, 'path': tma.img_path_tif, 'tif_fn': tma.name, 'patient_ID': cod_dts,'spot_ID': spot.ID,'label': l , 'spot_coord': spot.name}, ignore_index=True)          \n",
    "                    \n",
    "                else:\n",
    "                    m = m + ','+ str(spot.ID) +',not in bbdd '\n",
    "                    if verbose: print(m)\n",
    "            \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check, print all failed spots and its reasons (set verbose=True in process_tma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "check = False\n",
    "if check: \n",
    "    #run for sanity check, print all failed spots and its reasons (set verbose=True in process_tma)\n",
    "    ds = pd.DataFrame(columns=['tile', 'tile_rot_augmentation','path','tif_fn', 'patient_ID','label'])\n",
    "    for t in tmas:\n",
    "        res = process_tma(t, level = 4, verbose = True)\n",
    "        ds = pd.concat((ds,res))\n",
    "    ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "if check: \n",
    "    print(f' Usable spots: N spots, N biopsies included in TMAs and N patients {ds.shape[0], ds.spot_ID.nunique(), ds.patient_ID.nunique()}')\n",
    "    print(f' Usable spots MMR deficients: N spots, N biopsies and N patients {ds.loc[ds.label==1].shape[0],ds.loc[ds.label==1].spot_ID.nunique(),ds.loc[ds.label==1].patient_ID.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded TMAs\n"
     ]
    }
   ],
   "source": [
    "#noexport\n",
    "print('loaded TMAs') \n",
    "#for t in tmas: print(t.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save list of all spots available with associated information including spot coordenates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_level_4_QC = False\n",
    "if create_dataset_level_4_QC:\n",
    "    lev = 4\n",
    "    p_ds = f'dataset_level_{lev}_coordinates.csv'\n",
    "    ds = pd.read_csv(p_ds)\n",
    "    d = ds.merge(df_labels, how='left', left_on='patient_ID',right_on='COD_DTS', )\n",
    "\n",
    "    d.loc[d.COD_DTS.isna()] = d[['tile','tile_rot_augmentation','path', 'tif_fn','patient_ID','label', 'spot_coord']].merge(df_labels, how='left', left_on='patient_ID',right_on='BIOPSIA', )\n",
    "\n",
    "\n",
    "\n",
    "    #Drop duplicates after merge\n",
    "    d = d.loc[d[['tile','tif_fn']].astype(str).drop_duplicates(subset = ['tile', 'tif_fn']).index]\n",
    "    d.to_csv('dataset_level_4_QC.csv')\n",
    "    \n",
    "    #save list by patient \n",
    "    dp = d.loc[d[['patient_ID']].astype(str).drop_duplicates(subset = ['patient_ID']).index]\n",
    "    print(dp.shape)\n",
    "    dp.to_csv('dataset_level_4_patient_QC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save list of all spots available with associated information including spot coordenates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_level_4_QC = False\n",
    "if create_dataset_level_4_QC:\n",
    "    lev = 4\n",
    "    p_ds = f'dataset_level_{lev}_coordinates.csv'\n",
    "    ds = pd.read_csv(p_ds)\n",
    "    d = ds.merge(df_labels, how='left', left_on='patient_ID',right_on='COD_DTS', )\n",
    "\n",
    "    d.loc[d.COD_DTS.isna()] = d[['tile','tile_rot_augmentation','path', 'tif_fn','patient_ID','label', 'spot_coord']].merge(df_labels, how='left', left_on='patient_ID',right_on='BIOPSIA', )\n",
    "\n",
    "\n",
    "\n",
    "    #Drop duplicates after merge\n",
    "    d = d.loc[d[['tile','tif_fn']].astype(str).drop_duplicates(subset = ['tile', 'tif_fn']).index]\n",
    "    d.to_csv('dataset_level_4_QC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(level = 4):\n",
    "    lev = level\n",
    "    try:\n",
    "        p_ds = f'dataset_level_{lev}.csv'\n",
    "        ds = pd.read_csv(p_ds)\n",
    "        #ds = pd.concat([load_dataset(0)])\n",
    "        ds['tile']=ds['tile'].apply(eval)\n",
    "    except:\n",
    "        print('failed')\n",
    "        res = parallel(partial(process_tma,level = lev, verbose = False, label = 'MMR'),tmas)\n",
    "        ds = pd.concat((*res,))\n",
    "        #ds = process_tma(tmas[0], level = lev, verbose = False, label = 'MMR')\n",
    "        ds.to_csv(p_ds,index=False)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load New TMAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n"
     ]
    }
   ],
   "source": [
    "#d = pd.concat([load_dataset(0), load_dataset(1), load_dataset(2), load_dataset(3), load_dataset(4)])\n",
    "#fn = 'dataset_level_all_March21_no_overlap.csv'\n",
    "#fn = 'dataset_level_all_TMA20-013_no_overlap.csv'\n",
    "#d.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark Scarce tissue given a dataset of tissue labeled tiles saved in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1559775, 8)\n",
      "(957077, 12)\n"
     ]
    }
   ],
   "source": [
    "do_check = True\n",
    "if do_check:\n",
    "    import datatable as dt\n",
    "    import ast\n",
    "    import gc\n",
    "    from ast import literal_eval\n",
    "    dataset = ['TCGA', 'epicolon_other', 'epicolon_only_HGUA']\n",
    "    __p_csv = Path('dataset_level_all_TMA20-013_no_overlap_labeled_tissue.csv') #HGUA samples from TMA20-013\n",
    "    _p_csv = Path('dataset_level_all_March21_no_overlap_labeled_tissue.csv') #HGUA samples\n",
    "    p_csv = Path('dataset_level_all_no_overlap_labeled_tissue.csv') #Epicolon I and II\n",
    "    _p_csv_1 = Path('dataset_TCGA_MSI-H_level_0_no_overlap_labeled_tissue.csv') #TCGA MSI\n",
    "    _p_csv_0 = Path('dataset_TCGA_MSS_level_0_no_overlap_labeled_tissue.csv') #TCGA MSS\n",
    "\n",
    "    _d = pd.DataFrame()\n",
    "    d_t = pd.DataFrame()\n",
    "    de = pd.DataFrame()\n",
    "    if 'TCGA' in dataset  :\n",
    "        d_t = dt.fread(_p_csv_0).to_pandas()\n",
    "        print(d_t.shape)\n",
    "        _d_t = dt.fread(_p_csv_1).to_pandas()\n",
    "        d_t = pd.concat([d_t,_d_t])\n",
    "        d_t.shape #n tiles extracted from TCGA \n",
    "        d_t['project'] = 'TCGA'\n",
    "\n",
    "    if any(\"epicolon\" in s for s in dataset) :\n",
    "        de = dt.fread(p_csv).to_pandas()\n",
    "        print(de.shape)\n",
    "        _d = dt.fread(_p_csv).to_pandas()\n",
    "        __d = dt.fread(__p_csv).to_pandas()\n",
    "\n",
    "        d = pd.concat([de,_d,__d])\n",
    "        d.shape #n tiles extracted from EPICOLON I and II + HGUA  \n",
    "        #correct labels in two patients with mixed labels in source data (verified with AP)\n",
    "        d.loc[d.patient_ID == '13013', 'label'] = 2 #MSS\n",
    "        d.loc[d.patient_ID == '06B0014684A','label'] = 1 #MSI\n",
    "        d.loc[d.patient_ID == '05B0004750', 'label'] = 1 \n",
    "        d['project'] = 'epicolon'\n",
    "\n",
    "    d = pd.concat([d,d_t])\n",
    "    d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_fields(df):\n",
    "    df.tile = df.tile.apply(lambda x: eval(str(x)))\n",
    "    \n",
    "    df.loc[df.project == 'epicolon', 'tile_rot_augmentation'] = df.loc[df.project == 'epicolon'].tile_rot_augmentation.apply(lambda x: eval(str(x)))\n",
    "    return df\n",
    "\n",
    "if do_check:\n",
    "    df_split = np.array_split(d, 32)\n",
    "\n",
    "    res = parallel(partial(eval_fields), df_split)\n",
    "    d = pd.concat([*res])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(r):\n",
    "    img = None\n",
    "    if r.project == 'epicolon':\n",
    "        img = Spot.get_tile(Spot, *(r.tile), path=r.path, tif_name = r.tif_fn)\n",
    "    if r.project == 'TCGA':\n",
    "        img = WSI.get_tile(*(r.tile), path=r.path, svs_fn = r.svs_fn)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_scarce_tissue(df):\n",
    "    df['mean_rgb'] = df.apply(lambda x: Spot.check_scarce_tissue(get_x(x),  ret = 'mean'), axis = 1)\n",
    "    return df\n",
    "\n",
    "if do_check:\n",
    "    df_split = np.array_split(d, 32)\n",
    "\n",
    "    res = parallel(partial(eval_scarce_tissue), df_split)\n",
    "    d_mean_rgb = pd.concat([*res])\n",
    "    d_mean_rgb.to_csv('saved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/auri/anaconda3/envs/fastaiAP/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (3,5,6,7,9,11,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C0</th>\n",
       "      <th>tile</th>\n",
       "      <th>tile_rot_augmentation</th>\n",
       "      <th>path</th>\n",
       "      <th>tif_fn</th>\n",
       "      <th>patient_ID</th>\n",
       "      <th>spot_ID</th>\n",
       "      <th>label</th>\n",
       "      <th>spot_coord</th>\n",
       "      <th>zoom</th>\n",
       "      <th>clas_idx</th>\n",
       "      <th>probs</th>\n",
       "      <th>project</th>\n",
       "      <th>svs_fn</th>\n",
       "      <th>mean_rgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085771</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[9847, 5750, (300, 300), 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA/SVS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-AA-A02H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.01, 0.0, 0.05, 0.18, 0.0, 0.0, 0.0, 0.7, 0.07]</td>\n",
       "      <td>TCGA</td>\n",
       "      <td>TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1</td>\n",
       "      <td>83.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085772</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[9847, 6125, (300, 300), 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA/SVS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-AA-A02H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.01, 0.0, 0.61, 0.05, 0.01, 0.0, 0.26, 0.01, 0.06]</td>\n",
       "      <td>TCGA</td>\n",
       "      <td>TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1</td>\n",
       "      <td>38.750419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085773</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[10243, 6125, (300, 300), 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA/SVS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-AA-A02H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.02, 0.11, 0.0, 0.0, 0.03, 0.03, 0.81]</td>\n",
       "      <td>TCGA</td>\n",
       "      <td>TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1</td>\n",
       "      <td>102.691237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085774</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[10639, 6125, (300, 300), 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA/SVS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-AA-A02H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0, 0.5, 0.33]</td>\n",
       "      <td>TCGA</td>\n",
       "      <td>TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1</td>\n",
       "      <td>113.706996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085775</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[11035, 6125, (300, 300), 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA/SVS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-AA-A02H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.04, 0.0, 0.02, 0.13, 0.0, 0.0, 0.01, 0.64, 0.15]</td>\n",
       "      <td>TCGA</td>\n",
       "      <td>TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1</td>\n",
       "      <td>129.642111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  C0                          tile tile_rot_augmentation  \\\n",
       "1085771           0   0   [9847, 5750, (300, 300), 0]                   NaN   \n",
       "1085772           1   1   [9847, 6125, (300, 300), 0]                   NaN   \n",
       "1085773           2   2  [10243, 6125, (300, 300), 0]                   NaN   \n",
       "1085774           3   3  [10639, 6125, (300, 300), 0]                   NaN   \n",
       "1085775           4   4  [11035, 6125, (300, 300), 0]                   NaN   \n",
       "\n",
       "             path tif_fn    patient_ID spot_ID  label spot_coord  zoom  \\\n",
       "1085771  TCGA/SVS    NaN  TCGA-AA-A02H     NaN    2.0        NaN   NaN   \n",
       "1085772  TCGA/SVS    NaN  TCGA-AA-A02H     NaN    2.0        NaN   NaN   \n",
       "1085773  TCGA/SVS    NaN  TCGA-AA-A02H     NaN    2.0        NaN   NaN   \n",
       "1085774  TCGA/SVS    NaN  TCGA-AA-A02H     NaN    2.0        NaN   NaN   \n",
       "1085775  TCGA/SVS    NaN  TCGA-AA-A02H     NaN    2.0        NaN   NaN   \n",
       "\n",
       "        clas_idx                                                 probs  \\\n",
       "1085771        7     [0.01, 0.0, 0.05, 0.18, 0.0, 0.0, 0.0, 0.7, 0.07]   \n",
       "1085772        2  [0.01, 0.0, 0.61, 0.05, 0.01, 0.0, 0.26, 0.01, 0.06]   \n",
       "1085773        8    [0.0, 0.0, 0.02, 0.11, 0.0, 0.0, 0.03, 0.03, 0.81]   \n",
       "1085774        7       [0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0, 0.5, 0.33]   \n",
       "1085775        7   [0.04, 0.0, 0.02, 0.13, 0.0, 0.0, 0.01, 0.64, 0.15]   \n",
       "\n",
       "        project                                                        svs_fn  \\\n",
       "1085771    TCGA  TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1   \n",
       "1085772    TCGA  TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1   \n",
       "1085773    TCGA  TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1   \n",
       "1085774    TCGA  TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1   \n",
       "1085775    TCGA  TCGA-AA-A02H-01A-01-BS1.4a22c6cb-1222-4b9e-b884-85dd469be4b1   \n",
       "\n",
       "           mean_rgb  \n",
       "1085771   83.914300  \n",
       "1085772   38.750419  \n",
       "1085773  102.691237  \n",
       "1085774  113.706996  \n",
       "1085775  129.642111  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.read_csv('saved.csv')\n",
    "p.loc[p.project == 'TCGA'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
